{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.809451985922575,
  "eval_steps": 200,
  "global_step": 21500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05027652086475616,
      "grad_norm": 1.666865348815918,
      "learning_rate": 5e-06,
      "loss": 3.1557,
      "step": 100
    },
    {
      "epoch": 0.10055304172951232,
      "grad_norm": 1.7561618089675903,
      "learning_rate": 1e-05,
      "loss": 3.1174,
      "step": 200
    },
    {
      "epoch": 0.10055304172951232,
      "eval_loss": 3.046936511993408,
      "eval_runtime": 25.635,
      "eval_samples_per_second": 522.489,
      "eval_steps_per_second": 4.096,
      "step": 200
    },
    {
      "epoch": 0.15082956259426847,
      "grad_norm": 1.9091050624847412,
      "learning_rate": 1.5e-05,
      "loss": 3.0959,
      "step": 300
    },
    {
      "epoch": 0.20110608345902464,
      "grad_norm": 1.9237169027328491,
      "learning_rate": 2e-05,
      "loss": 3.0798,
      "step": 400
    },
    {
      "epoch": 0.20110608345902464,
      "eval_loss": 3.020580291748047,
      "eval_runtime": 25.6943,
      "eval_samples_per_second": 521.284,
      "eval_steps_per_second": 4.087,
      "step": 400
    },
    {
      "epoch": 0.2513826043237808,
      "grad_norm": 1.9071722030639648,
      "learning_rate": 2.5e-05,
      "loss": 3.0708,
      "step": 500
    },
    {
      "epoch": 0.30165912518853694,
      "grad_norm": 1.9233018159866333,
      "learning_rate": 3e-05,
      "loss": 3.0629,
      "step": 600
    },
    {
      "epoch": 0.30165912518853694,
      "eval_loss": 3.0083577632904053,
      "eval_runtime": 25.6446,
      "eval_samples_per_second": 522.293,
      "eval_steps_per_second": 4.094,
      "step": 600
    },
    {
      "epoch": 0.35193564605329314,
      "grad_norm": 1.8891584873199463,
      "learning_rate": 3.5e-05,
      "loss": 3.0491,
      "step": 700
    },
    {
      "epoch": 0.4022121669180493,
      "grad_norm": 1.9060579538345337,
      "learning_rate": 4e-05,
      "loss": 3.0464,
      "step": 800
    },
    {
      "epoch": 0.4022121669180493,
      "eval_loss": 2.9939987659454346,
      "eval_runtime": 25.6851,
      "eval_samples_per_second": 521.47,
      "eval_steps_per_second": 4.088,
      "step": 800
    },
    {
      "epoch": 0.45248868778280543,
      "grad_norm": 2.0871989727020264,
      "learning_rate": 4.5e-05,
      "loss": 3.0436,
      "step": 900
    },
    {
      "epoch": 0.5027652086475616,
      "grad_norm": 2.0378918647766113,
      "learning_rate": 5e-05,
      "loss": 3.0349,
      "step": 1000
    },
    {
      "epoch": 0.5027652086475616,
      "eval_loss": 2.9850919246673584,
      "eval_runtime": 25.711,
      "eval_samples_per_second": 520.944,
      "eval_steps_per_second": 4.084,
      "step": 1000
    },
    {
      "epoch": 0.5530417295123178,
      "grad_norm": 1.989633321762085,
      "learning_rate": 4.997473471450228e-05,
      "loss": 3.0217,
      "step": 1100
    },
    {
      "epoch": 0.6033182503770739,
      "grad_norm": 1.9221757650375366,
      "learning_rate": 4.994946942900455e-05,
      "loss": 2.9911,
      "step": 1200
    },
    {
      "epoch": 0.6033182503770739,
      "eval_loss": 2.965416669845581,
      "eval_runtime": 25.6242,
      "eval_samples_per_second": 522.708,
      "eval_steps_per_second": 4.098,
      "step": 1200
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 1.8727033138275146,
      "learning_rate": 4.9924204143506826e-05,
      "loss": 2.982,
      "step": 1300
    },
    {
      "epoch": 0.7038712921065863,
      "grad_norm": 2.0091428756713867,
      "learning_rate": 4.98989388580091e-05,
      "loss": 2.9661,
      "step": 1400
    },
    {
      "epoch": 0.7038712921065863,
      "eval_loss": 2.9428088665008545,
      "eval_runtime": 25.5411,
      "eval_samples_per_second": 524.41,
      "eval_steps_per_second": 4.111,
      "step": 1400
    },
    {
      "epoch": 0.7541478129713424,
      "grad_norm": 1.918994426727295,
      "learning_rate": 4.987367357251137e-05,
      "loss": 2.9612,
      "step": 1500
    },
    {
      "epoch": 0.8044243338360986,
      "grad_norm": 1.900664210319519,
      "learning_rate": 4.984840828701365e-05,
      "loss": 2.9408,
      "step": 1600
    },
    {
      "epoch": 0.8044243338360986,
      "eval_loss": 2.920032262802124,
      "eval_runtime": 25.5104,
      "eval_samples_per_second": 525.04,
      "eval_steps_per_second": 4.116,
      "step": 1600
    },
    {
      "epoch": 0.8547008547008547,
      "grad_norm": 1.8770358562469482,
      "learning_rate": 4.982314300151592e-05,
      "loss": 2.9292,
      "step": 1700
    },
    {
      "epoch": 0.9049773755656109,
      "grad_norm": 4.632493019104004,
      "learning_rate": 4.979787771601819e-05,
      "loss": 2.9132,
      "step": 1800
    },
    {
      "epoch": 0.9049773755656109,
      "eval_loss": 2.9100492000579834,
      "eval_runtime": 25.5801,
      "eval_samples_per_second": 523.611,
      "eval_steps_per_second": 4.105,
      "step": 1800
    },
    {
      "epoch": 0.9552538964303671,
      "grad_norm": 2.6963138580322266,
      "learning_rate": 4.9772612430520465e-05,
      "loss": 2.9209,
      "step": 1900
    },
    {
      "epoch": 1.0055304172951232,
      "grad_norm": 1.9743242263793945,
      "learning_rate": 4.9747347145022746e-05,
      "loss": 2.9351,
      "step": 2000
    },
    {
      "epoch": 1.0055304172951232,
      "eval_loss": 2.882725715637207,
      "eval_runtime": 25.6226,
      "eval_samples_per_second": 522.741,
      "eval_steps_per_second": 4.098,
      "step": 2000
    },
    {
      "epoch": 1.0558069381598794,
      "grad_norm": 2.665703296661377,
      "learning_rate": 4.9722081859525014e-05,
      "loss": 2.8776,
      "step": 2100
    },
    {
      "epoch": 1.1060834590246356,
      "grad_norm": 2.564103603363037,
      "learning_rate": 4.969681657402729e-05,
      "loss": 2.8748,
      "step": 2200
    },
    {
      "epoch": 1.1060834590246356,
      "eval_loss": 2.869079113006592,
      "eval_runtime": 25.5109,
      "eval_samples_per_second": 525.031,
      "eval_steps_per_second": 4.116,
      "step": 2200
    },
    {
      "epoch": 1.1563599798893915,
      "grad_norm": 2.089341640472412,
      "learning_rate": 4.967155128852956e-05,
      "loss": 2.8772,
      "step": 2300
    },
    {
      "epoch": 1.2066365007541477,
      "grad_norm": 2.423740863800049,
      "learning_rate": 4.964628600303184e-05,
      "loss": 2.8624,
      "step": 2400
    },
    {
      "epoch": 1.2066365007541477,
      "eval_loss": 2.853231430053711,
      "eval_runtime": 25.5637,
      "eval_samples_per_second": 523.947,
      "eval_steps_per_second": 4.107,
      "step": 2400
    },
    {
      "epoch": 1.256913021618904,
      "grad_norm": 2.1258156299591064,
      "learning_rate": 4.962102071753411e-05,
      "loss": 2.855,
      "step": 2500
    },
    {
      "epoch": 1.3071895424836601,
      "grad_norm": 2.0990540981292725,
      "learning_rate": 4.9595755432036386e-05,
      "loss": 2.8528,
      "step": 2600
    },
    {
      "epoch": 1.3071895424836601,
      "eval_loss": 2.843825101852417,
      "eval_runtime": 25.584,
      "eval_samples_per_second": 523.531,
      "eval_steps_per_second": 4.104,
      "step": 2600
    },
    {
      "epoch": 1.3574660633484164,
      "grad_norm": 1.9205808639526367,
      "learning_rate": 4.957049014653865e-05,
      "loss": 2.8512,
      "step": 2700
    },
    {
      "epoch": 1.4077425842131723,
      "grad_norm": 3.9723684787750244,
      "learning_rate": 4.9545224861040934e-05,
      "loss": 2.8513,
      "step": 2800
    },
    {
      "epoch": 1.4077425842131723,
      "eval_loss": 2.831146717071533,
      "eval_runtime": 25.5796,
      "eval_samples_per_second": 523.62,
      "eval_steps_per_second": 4.105,
      "step": 2800
    },
    {
      "epoch": 1.4580191050779285,
      "grad_norm": 1.9718807935714722,
      "learning_rate": 4.951995957554321e-05,
      "loss": 2.8322,
      "step": 2900
    },
    {
      "epoch": 1.5082956259426847,
      "grad_norm": 1.8991053104400635,
      "learning_rate": 4.9494694290045476e-05,
      "loss": 2.839,
      "step": 3000
    },
    {
      "epoch": 1.5082956259426847,
      "eval_loss": 2.8129210472106934,
      "eval_runtime": 25.5857,
      "eval_samples_per_second": 523.495,
      "eval_steps_per_second": 4.104,
      "step": 3000
    },
    {
      "epoch": 1.558572146807441,
      "grad_norm": 1.900040864944458,
      "learning_rate": 4.946942900454775e-05,
      "loss": 2.836,
      "step": 3100
    },
    {
      "epoch": 1.6088486676721971,
      "grad_norm": 2.159252882003784,
      "learning_rate": 4.944416371905003e-05,
      "loss": 2.828,
      "step": 3200
    },
    {
      "epoch": 1.6088486676721971,
      "eval_loss": 2.802943706512451,
      "eval_runtime": 25.7005,
      "eval_samples_per_second": 521.158,
      "eval_steps_per_second": 4.086,
      "step": 3200
    },
    {
      "epoch": 1.6591251885369531,
      "grad_norm": 2.014819383621216,
      "learning_rate": 4.94188984335523e-05,
      "loss": 2.818,
      "step": 3300
    },
    {
      "epoch": 1.7094017094017095,
      "grad_norm": 2.0802183151245117,
      "learning_rate": 4.9393633148054574e-05,
      "loss": 2.8104,
      "step": 3400
    },
    {
      "epoch": 1.7094017094017095,
      "eval_loss": 2.790073871612549,
      "eval_runtime": 25.6462,
      "eval_samples_per_second": 522.26,
      "eval_steps_per_second": 4.094,
      "step": 3400
    },
    {
      "epoch": 1.7596782302664655,
      "grad_norm": 1.9060359001159668,
      "learning_rate": 4.936836786255685e-05,
      "loss": 2.8103,
      "step": 3500
    },
    {
      "epoch": 1.8099547511312217,
      "grad_norm": 1.8757869005203247,
      "learning_rate": 4.934310257705912e-05,
      "loss": 2.8015,
      "step": 3600
    },
    {
      "epoch": 1.8099547511312217,
      "eval_loss": 2.779996156692505,
      "eval_runtime": 25.659,
      "eval_samples_per_second": 521.999,
      "eval_steps_per_second": 4.092,
      "step": 3600
    },
    {
      "epoch": 1.860231271995978,
      "grad_norm": 1.9013962745666504,
      "learning_rate": 4.93178372915614e-05,
      "loss": 2.8007,
      "step": 3700
    },
    {
      "epoch": 1.910507792860734,
      "grad_norm": 1.9137316942214966,
      "learning_rate": 4.929257200606367e-05,
      "loss": 2.8001,
      "step": 3800
    },
    {
      "epoch": 1.910507792860734,
      "eval_loss": 2.7736618518829346,
      "eval_runtime": 25.6548,
      "eval_samples_per_second": 522.085,
      "eval_steps_per_second": 4.093,
      "step": 3800
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 2.2100589275360107,
      "learning_rate": 4.926730672056594e-05,
      "loss": 2.8,
      "step": 3900
    },
    {
      "epoch": 2.0110608345902463,
      "grad_norm": 2.8723244667053223,
      "learning_rate": 4.924204143506822e-05,
      "loss": 2.7778,
      "step": 4000
    },
    {
      "epoch": 2.0110608345902463,
      "eval_loss": 2.766834020614624,
      "eval_runtime": 25.6047,
      "eval_samples_per_second": 523.107,
      "eval_steps_per_second": 4.101,
      "step": 4000
    },
    {
      "epoch": 2.0613373554550023,
      "grad_norm": 1.8652105331420898,
      "learning_rate": 4.9216776149570495e-05,
      "loss": 2.7247,
      "step": 4100
    },
    {
      "epoch": 2.1116138763197587,
      "grad_norm": 1.8043776750564575,
      "learning_rate": 4.919151086407276e-05,
      "loss": 2.7549,
      "step": 4200
    },
    {
      "epoch": 2.1116138763197587,
      "eval_loss": 2.785613775253296,
      "eval_runtime": 25.599,
      "eval_samples_per_second": 523.223,
      "eval_steps_per_second": 4.102,
      "step": 4200
    },
    {
      "epoch": 2.1618903971845147,
      "grad_norm": 1.968974232673645,
      "learning_rate": 4.9166245578575037e-05,
      "loss": 2.7367,
      "step": 4300
    },
    {
      "epoch": 2.212166918049271,
      "grad_norm": 2.114194869995117,
      "learning_rate": 4.914098029307732e-05,
      "loss": 2.7198,
      "step": 4400
    },
    {
      "epoch": 2.212166918049271,
      "eval_loss": 2.7504324913024902,
      "eval_runtime": 25.5146,
      "eval_samples_per_second": 524.954,
      "eval_steps_per_second": 4.115,
      "step": 4400
    },
    {
      "epoch": 2.262443438914027,
      "grad_norm": 2.002854347229004,
      "learning_rate": 4.9115715007579585e-05,
      "loss": 2.7243,
      "step": 4500
    },
    {
      "epoch": 2.312719959778783,
      "grad_norm": 2.05568265914917,
      "learning_rate": 4.909044972208186e-05,
      "loss": 2.7163,
      "step": 4600
    },
    {
      "epoch": 2.312719959778783,
      "eval_loss": 2.7428641319274902,
      "eval_runtime": 25.6838,
      "eval_samples_per_second": 521.496,
      "eval_steps_per_second": 4.088,
      "step": 4600
    },
    {
      "epoch": 2.3629964806435395,
      "grad_norm": 1.8246495723724365,
      "learning_rate": 4.906518443658414e-05,
      "loss": 2.7263,
      "step": 4700
    },
    {
      "epoch": 2.4132730015082955,
      "grad_norm": 1.9651747941970825,
      "learning_rate": 4.903991915108641e-05,
      "loss": 2.7168,
      "step": 4800
    },
    {
      "epoch": 2.4132730015082955,
      "eval_loss": 2.7383055686950684,
      "eval_runtime": 25.7138,
      "eval_samples_per_second": 520.888,
      "eval_steps_per_second": 4.083,
      "step": 4800
    },
    {
      "epoch": 2.463549522373052,
      "grad_norm": 1.9141066074371338,
      "learning_rate": 4.901465386558868e-05,
      "loss": 2.7214,
      "step": 4900
    },
    {
      "epoch": 2.513826043237808,
      "grad_norm": 1.9556431770324707,
      "learning_rate": 4.898938858009096e-05,
      "loss": 2.7145,
      "step": 5000
    },
    {
      "epoch": 2.513826043237808,
      "eval_loss": 2.728815793991089,
      "eval_runtime": 26.054,
      "eval_samples_per_second": 514.087,
      "eval_steps_per_second": 4.03,
      "step": 5000
    },
    {
      "epoch": 2.564102564102564,
      "grad_norm": 1.9812490940093994,
      "learning_rate": 4.896412329459323e-05,
      "loss": 2.7083,
      "step": 5100
    },
    {
      "epoch": 2.6143790849673203,
      "grad_norm": 1.8086082935333252,
      "learning_rate": 4.8938858009095506e-05,
      "loss": 2.7173,
      "step": 5200
    },
    {
      "epoch": 2.6143790849673203,
      "eval_loss": 2.7206475734710693,
      "eval_runtime": 25.6166,
      "eval_samples_per_second": 522.865,
      "eval_steps_per_second": 4.099,
      "step": 5200
    },
    {
      "epoch": 2.6646556058320763,
      "grad_norm": 2.081789255142212,
      "learning_rate": 4.891359272359778e-05,
      "loss": 2.7074,
      "step": 5300
    },
    {
      "epoch": 2.7149321266968327,
      "grad_norm": 1.822044849395752,
      "learning_rate": 4.888832743810005e-05,
      "loss": 2.7105,
      "step": 5400
    },
    {
      "epoch": 2.7149321266968327,
      "eval_loss": 2.716498613357544,
      "eval_runtime": 25.5584,
      "eval_samples_per_second": 524.056,
      "eval_steps_per_second": 4.108,
      "step": 5400
    },
    {
      "epoch": 2.7652086475615887,
      "grad_norm": 2.001115322113037,
      "learning_rate": 4.886306215260233e-05,
      "loss": 2.7054,
      "step": 5500
    },
    {
      "epoch": 2.8154851684263447,
      "grad_norm": 1.9068005084991455,
      "learning_rate": 4.8837796867104603e-05,
      "loss": 2.6992,
      "step": 5600
    },
    {
      "epoch": 2.8154851684263447,
      "eval_loss": 2.713592052459717,
      "eval_runtime": 25.6044,
      "eval_samples_per_second": 523.114,
      "eval_steps_per_second": 4.101,
      "step": 5600
    },
    {
      "epoch": 2.865761689291101,
      "grad_norm": 9.174367904663086,
      "learning_rate": 4.881253158160687e-05,
      "loss": 2.6939,
      "step": 5700
    },
    {
      "epoch": 2.916038210155857,
      "grad_norm": 1.8221274614334106,
      "learning_rate": 4.8787266296109145e-05,
      "loss": 2.6963,
      "step": 5800
    },
    {
      "epoch": 2.916038210155857,
      "eval_loss": 2.6999828815460205,
      "eval_runtime": 25.6882,
      "eval_samples_per_second": 521.407,
      "eval_steps_per_second": 4.087,
      "step": 5800
    },
    {
      "epoch": 2.9663147310206135,
      "grad_norm": 1.8699740171432495,
      "learning_rate": 4.8762001010611427e-05,
      "loss": 2.6963,
      "step": 5900
    },
    {
      "epoch": 3.0165912518853695,
      "grad_norm": 1.780759334564209,
      "learning_rate": 4.8736735725113694e-05,
      "loss": 2.663,
      "step": 6000
    },
    {
      "epoch": 3.0165912518853695,
      "eval_loss": 2.6976168155670166,
      "eval_runtime": 25.6224,
      "eval_samples_per_second": 522.745,
      "eval_steps_per_second": 4.098,
      "step": 6000
    },
    {
      "epoch": 3.066867772750126,
      "grad_norm": 1.7881214618682861,
      "learning_rate": 4.871147043961597e-05,
      "loss": 2.6109,
      "step": 6100
    },
    {
      "epoch": 3.117144293614882,
      "grad_norm": 1.89806067943573,
      "learning_rate": 4.868620515411824e-05,
      "loss": 2.6099,
      "step": 6200
    },
    {
      "epoch": 3.117144293614882,
      "eval_loss": 2.691361427307129,
      "eval_runtime": 25.6499,
      "eval_samples_per_second": 522.185,
      "eval_steps_per_second": 4.094,
      "step": 6200
    },
    {
      "epoch": 3.167420814479638,
      "grad_norm": 3.9822230339050293,
      "learning_rate": 4.866093986862052e-05,
      "loss": 2.6123,
      "step": 6300
    },
    {
      "epoch": 3.2176973353443943,
      "grad_norm": 2.0798723697662354,
      "learning_rate": 4.863567458312279e-05,
      "loss": 2.6278,
      "step": 6400
    },
    {
      "epoch": 3.2176973353443943,
      "eval_loss": 2.6871774196624756,
      "eval_runtime": 25.5948,
      "eval_samples_per_second": 523.31,
      "eval_steps_per_second": 4.102,
      "step": 6400
    },
    {
      "epoch": 3.2679738562091503,
      "grad_norm": 2.0685999393463135,
      "learning_rate": 4.8610409297625066e-05,
      "loss": 2.6213,
      "step": 6500
    },
    {
      "epoch": 3.3182503770739062,
      "grad_norm": 2.0529515743255615,
      "learning_rate": 4.858514401212734e-05,
      "loss": 2.6228,
      "step": 6600
    },
    {
      "epoch": 3.3182503770739062,
      "eval_loss": 2.6828596591949463,
      "eval_runtime": 25.6345,
      "eval_samples_per_second": 522.499,
      "eval_steps_per_second": 4.096,
      "step": 6600
    },
    {
      "epoch": 3.3685268979386627,
      "grad_norm": 1.8676843643188477,
      "learning_rate": 4.8559878726629615e-05,
      "loss": 2.6207,
      "step": 6700
    },
    {
      "epoch": 3.4188034188034186,
      "grad_norm": 2.4633965492248535,
      "learning_rate": 4.853461344113189e-05,
      "loss": 2.6197,
      "step": 6800
    },
    {
      "epoch": 3.4188034188034186,
      "eval_loss": 2.675445318222046,
      "eval_runtime": 25.6825,
      "eval_samples_per_second": 521.522,
      "eval_steps_per_second": 4.088,
      "step": 6800
    },
    {
      "epoch": 3.469079939668175,
      "grad_norm": 2.296401262283325,
      "learning_rate": 4.850934815563416e-05,
      "loss": 2.6216,
      "step": 6900
    },
    {
      "epoch": 3.519356460532931,
      "grad_norm": 2.1584222316741943,
      "learning_rate": 4.848408287013643e-05,
      "loss": 2.6138,
      "step": 7000
    },
    {
      "epoch": 3.519356460532931,
      "eval_loss": 2.674447774887085,
      "eval_runtime": 25.602,
      "eval_samples_per_second": 523.163,
      "eval_steps_per_second": 4.101,
      "step": 7000
    },
    {
      "epoch": 3.569632981397687,
      "grad_norm": 1.9989453554153442,
      "learning_rate": 4.845881758463871e-05,
      "loss": 2.6129,
      "step": 7100
    },
    {
      "epoch": 3.6199095022624435,
      "grad_norm": 2.064603805541992,
      "learning_rate": 4.843355229914098e-05,
      "loss": 2.6237,
      "step": 7200
    },
    {
      "epoch": 3.6199095022624435,
      "eval_loss": 2.669757843017578,
      "eval_runtime": 25.6437,
      "eval_samples_per_second": 522.311,
      "eval_steps_per_second": 4.095,
      "step": 7200
    },
    {
      "epoch": 3.6701860231271994,
      "grad_norm": 1.8811675310134888,
      "learning_rate": 4.8408287013643254e-05,
      "loss": 2.6269,
      "step": 7300
    },
    {
      "epoch": 3.720462543991956,
      "grad_norm": 1.9165029525756836,
      "learning_rate": 4.838302172814553e-05,
      "loss": 2.6157,
      "step": 7400
    },
    {
      "epoch": 3.720462543991956,
      "eval_loss": 2.664517402648926,
      "eval_runtime": 25.596,
      "eval_samples_per_second": 523.286,
      "eval_steps_per_second": 4.102,
      "step": 7400
    },
    {
      "epoch": 3.770739064856712,
      "grad_norm": 1.7279680967330933,
      "learning_rate": 4.83577564426478e-05,
      "loss": 2.6207,
      "step": 7500
    },
    {
      "epoch": 3.821015585721468,
      "grad_norm": 1.876684308052063,
      "learning_rate": 4.833249115715008e-05,
      "loss": 2.6122,
      "step": 7600
    },
    {
      "epoch": 3.821015585721468,
      "eval_loss": 2.6596641540527344,
      "eval_runtime": 25.5296,
      "eval_samples_per_second": 524.646,
      "eval_steps_per_second": 4.113,
      "step": 7600
    },
    {
      "epoch": 3.8712921065862242,
      "grad_norm": 1.869599461555481,
      "learning_rate": 4.830722587165235e-05,
      "loss": 2.6193,
      "step": 7700
    },
    {
      "epoch": 3.9215686274509802,
      "grad_norm": 1.8105998039245605,
      "learning_rate": 4.8281960586154626e-05,
      "loss": 2.6161,
      "step": 7800
    },
    {
      "epoch": 3.9215686274509802,
      "eval_loss": 2.657623529434204,
      "eval_runtime": 25.5627,
      "eval_samples_per_second": 523.966,
      "eval_steps_per_second": 4.108,
      "step": 7800
    },
    {
      "epoch": 3.9718451483157367,
      "grad_norm": 1.8324179649353027,
      "learning_rate": 4.82566953006569e-05,
      "loss": 2.6062,
      "step": 7900
    },
    {
      "epoch": 4.022121669180493,
      "grad_norm": 1.8655427694320679,
      "learning_rate": 4.8231430015159175e-05,
      "loss": 2.5715,
      "step": 8000
    },
    {
      "epoch": 4.022121669180493,
      "eval_loss": 2.6482114791870117,
      "eval_runtime": 25.5075,
      "eval_samples_per_second": 525.101,
      "eval_steps_per_second": 4.116,
      "step": 8000
    },
    {
      "epoch": 4.072398190045249,
      "grad_norm": 2.0711052417755127,
      "learning_rate": 4.820616472966145e-05,
      "loss": 2.5351,
      "step": 8100
    },
    {
      "epoch": 4.122674710910005,
      "grad_norm": 2.3921709060668945,
      "learning_rate": 4.8180899444163724e-05,
      "loss": 2.5268,
      "step": 8200
    },
    {
      "epoch": 4.122674710910005,
      "eval_loss": 2.6511220932006836,
      "eval_runtime": 25.6969,
      "eval_samples_per_second": 521.23,
      "eval_steps_per_second": 4.086,
      "step": 8200
    },
    {
      "epoch": 4.1729512317747615,
      "grad_norm": 2.0377094745635986,
      "learning_rate": 4.8155634158666e-05,
      "loss": 2.5256,
      "step": 8300
    },
    {
      "epoch": 4.223227752639517,
      "grad_norm": 1.8668097257614136,
      "learning_rate": 4.8130368873168266e-05,
      "loss": 2.5297,
      "step": 8400
    },
    {
      "epoch": 4.223227752639517,
      "eval_loss": 2.6472127437591553,
      "eval_runtime": 25.5666,
      "eval_samples_per_second": 523.887,
      "eval_steps_per_second": 4.107,
      "step": 8400
    },
    {
      "epoch": 4.273504273504273,
      "grad_norm": 1.9746530055999756,
      "learning_rate": 4.810510358767054e-05,
      "loss": 2.531,
      "step": 8500
    },
    {
      "epoch": 4.323780794369029,
      "grad_norm": 2.1057651042938232,
      "learning_rate": 4.807983830217282e-05,
      "loss": 2.5395,
      "step": 8600
    },
    {
      "epoch": 4.323780794369029,
      "eval_loss": 2.6423590183258057,
      "eval_runtime": 25.6619,
      "eval_samples_per_second": 521.941,
      "eval_steps_per_second": 4.092,
      "step": 8600
    },
    {
      "epoch": 4.374057315233786,
      "grad_norm": 1.8959227800369263,
      "learning_rate": 4.805457301667509e-05,
      "loss": 2.5396,
      "step": 8700
    },
    {
      "epoch": 4.424333836098542,
      "grad_norm": 1.956717610359192,
      "learning_rate": 4.802930773117736e-05,
      "loss": 2.5286,
      "step": 8800
    },
    {
      "epoch": 4.424333836098542,
      "eval_loss": 2.63950777053833,
      "eval_runtime": 25.5992,
      "eval_samples_per_second": 523.219,
      "eval_steps_per_second": 4.102,
      "step": 8800
    },
    {
      "epoch": 4.474610356963298,
      "grad_norm": 1.9068067073822021,
      "learning_rate": 4.800404244567964e-05,
      "loss": 2.5386,
      "step": 8900
    },
    {
      "epoch": 4.524886877828054,
      "grad_norm": 1.925269365310669,
      "learning_rate": 4.797877716018191e-05,
      "loss": 2.5356,
      "step": 9000
    },
    {
      "epoch": 4.524886877828054,
      "eval_loss": 2.636136293411255,
      "eval_runtime": 25.6395,
      "eval_samples_per_second": 522.397,
      "eval_steps_per_second": 4.095,
      "step": 9000
    },
    {
      "epoch": 4.57516339869281,
      "grad_norm": 1.9525351524353027,
      "learning_rate": 4.7953511874684186e-05,
      "loss": 2.5437,
      "step": 9100
    },
    {
      "epoch": 4.625439919557566,
      "grad_norm": 1.9370908737182617,
      "learning_rate": 4.792824658918646e-05,
      "loss": 2.5439,
      "step": 9200
    },
    {
      "epoch": 4.625439919557566,
      "eval_loss": 2.6290297508239746,
      "eval_runtime": 25.5584,
      "eval_samples_per_second": 524.055,
      "eval_steps_per_second": 4.108,
      "step": 9200
    },
    {
      "epoch": 4.675716440422323,
      "grad_norm": 1.9106333255767822,
      "learning_rate": 4.7902981303688735e-05,
      "loss": 2.5392,
      "step": 9300
    },
    {
      "epoch": 4.725992961287079,
      "grad_norm": 2.419008493423462,
      "learning_rate": 4.787771601819101e-05,
      "loss": 2.533,
      "step": 9400
    },
    {
      "epoch": 4.725992961287079,
      "eval_loss": 2.626742124557495,
      "eval_runtime": 25.5811,
      "eval_samples_per_second": 523.589,
      "eval_steps_per_second": 4.105,
      "step": 9400
    },
    {
      "epoch": 4.776269482151835,
      "grad_norm": 1.8807916641235352,
      "learning_rate": 4.7852450732693284e-05,
      "loss": 2.5349,
      "step": 9500
    },
    {
      "epoch": 4.826546003016591,
      "grad_norm": 1.884757399559021,
      "learning_rate": 4.782718544719556e-05,
      "loss": 2.544,
      "step": 9600
    },
    {
      "epoch": 4.826546003016591,
      "eval_loss": 2.6250925064086914,
      "eval_runtime": 25.6998,
      "eval_samples_per_second": 521.172,
      "eval_steps_per_second": 4.086,
      "step": 9600
    },
    {
      "epoch": 4.876822523881348,
      "grad_norm": 1.846232295036316,
      "learning_rate": 4.7801920161697826e-05,
      "loss": 2.5402,
      "step": 9700
    },
    {
      "epoch": 4.927099044746104,
      "grad_norm": 1.7839720249176025,
      "learning_rate": 4.777665487620011e-05,
      "loss": 2.534,
      "step": 9800
    },
    {
      "epoch": 4.927099044746104,
      "eval_loss": 2.623291015625,
      "eval_runtime": 25.6358,
      "eval_samples_per_second": 522.472,
      "eval_steps_per_second": 4.096,
      "step": 9800
    },
    {
      "epoch": 4.97737556561086,
      "grad_norm": 2.8889920711517334,
      "learning_rate": 4.7751389590702375e-05,
      "loss": 2.531,
      "step": 9900
    },
    {
      "epoch": 5.027652086475616,
      "grad_norm": 2.136988878250122,
      "learning_rate": 4.772612430520465e-05,
      "loss": 2.4781,
      "step": 10000
    },
    {
      "epoch": 5.027652086475616,
      "eval_loss": 2.6207027435302734,
      "eval_runtime": 25.9212,
      "eval_samples_per_second": 516.72,
      "eval_steps_per_second": 4.051,
      "step": 10000
    },
    {
      "epoch": 5.077928607340372,
      "grad_norm": 2.218360424041748,
      "learning_rate": 4.770085901970692e-05,
      "loss": 2.4368,
      "step": 10100
    },
    {
      "epoch": 5.128205128205128,
      "grad_norm": 2.100844144821167,
      "learning_rate": 4.76755937342092e-05,
      "loss": 2.4475,
      "step": 10200
    },
    {
      "epoch": 5.128205128205128,
      "eval_loss": 2.622487783432007,
      "eval_runtime": 25.628,
      "eval_samples_per_second": 522.631,
      "eval_steps_per_second": 4.097,
      "step": 10200
    },
    {
      "epoch": 5.178481649069885,
      "grad_norm": 2.038576126098633,
      "learning_rate": 4.765032844871147e-05,
      "loss": 2.4434,
      "step": 10300
    },
    {
      "epoch": 5.228758169934641,
      "grad_norm": 2.021735191345215,
      "learning_rate": 4.7625063163213746e-05,
      "loss": 2.4585,
      "step": 10400
    },
    {
      "epoch": 5.228758169934641,
      "eval_loss": 2.6201672554016113,
      "eval_runtime": 25.602,
      "eval_samples_per_second": 523.162,
      "eval_steps_per_second": 4.101,
      "step": 10400
    },
    {
      "epoch": 5.279034690799397,
      "grad_norm": 2.105374336242676,
      "learning_rate": 4.759979787771602e-05,
      "loss": 2.4486,
      "step": 10500
    },
    {
      "epoch": 5.329311211664153,
      "grad_norm": 2.5575146675109863,
      "learning_rate": 4.7574532592218295e-05,
      "loss": 2.4506,
      "step": 10600
    },
    {
      "epoch": 5.329311211664153,
      "eval_loss": 2.618279218673706,
      "eval_runtime": 25.6134,
      "eval_samples_per_second": 522.929,
      "eval_steps_per_second": 4.099,
      "step": 10600
    },
    {
      "epoch": 5.379587732528909,
      "grad_norm": 1.992971420288086,
      "learning_rate": 4.754926730672057e-05,
      "loss": 2.4608,
      "step": 10700
    },
    {
      "epoch": 5.429864253393665,
      "grad_norm": 2.263979911804199,
      "learning_rate": 4.7524002021222844e-05,
      "loss": 2.4635,
      "step": 10800
    },
    {
      "epoch": 5.429864253393665,
      "eval_loss": 2.6152822971343994,
      "eval_runtime": 25.6477,
      "eval_samples_per_second": 522.231,
      "eval_steps_per_second": 4.094,
      "step": 10800
    },
    {
      "epoch": 5.480140774258421,
      "grad_norm": 2.004784345626831,
      "learning_rate": 4.749873673572511e-05,
      "loss": 2.4709,
      "step": 10900
    },
    {
      "epoch": 5.530417295123177,
      "grad_norm": 2.130988121032715,
      "learning_rate": 4.747347145022739e-05,
      "loss": 2.4673,
      "step": 11000
    },
    {
      "epoch": 5.530417295123177,
      "eval_loss": 2.614903688430786,
      "eval_runtime": 25.6341,
      "eval_samples_per_second": 522.506,
      "eval_steps_per_second": 4.096,
      "step": 11000
    },
    {
      "epoch": 5.580693815987933,
      "grad_norm": 2.0636215209960938,
      "learning_rate": 4.744820616472967e-05,
      "loss": 2.4658,
      "step": 11100
    },
    {
      "epoch": 5.630970336852689,
      "grad_norm": 2.0251426696777344,
      "learning_rate": 4.7422940879231935e-05,
      "loss": 2.4688,
      "step": 11200
    },
    {
      "epoch": 5.630970336852689,
      "eval_loss": 2.6106276512145996,
      "eval_runtime": 25.6393,
      "eval_samples_per_second": 522.402,
      "eval_steps_per_second": 4.095,
      "step": 11200
    },
    {
      "epoch": 5.681246857717446,
      "grad_norm": 1.9515289068222046,
      "learning_rate": 4.739767559373421e-05,
      "loss": 2.4675,
      "step": 11300
    },
    {
      "epoch": 5.731523378582202,
      "grad_norm": 1.9804339408874512,
      "learning_rate": 4.7372410308236483e-05,
      "loss": 2.4649,
      "step": 11400
    },
    {
      "epoch": 5.731523378582202,
      "eval_loss": 2.6082723140716553,
      "eval_runtime": 25.5486,
      "eval_samples_per_second": 524.255,
      "eval_steps_per_second": 4.11,
      "step": 11400
    },
    {
      "epoch": 5.781799899446958,
      "grad_norm": 1.8991003036499023,
      "learning_rate": 4.734714502273876e-05,
      "loss": 2.4656,
      "step": 11500
    },
    {
      "epoch": 5.832076420311714,
      "grad_norm": 8.839363098144531,
      "learning_rate": 4.732187973724103e-05,
      "loss": 2.4661,
      "step": 11600
    },
    {
      "epoch": 5.832076420311714,
      "eval_loss": 2.608595609664917,
      "eval_runtime": 25.6864,
      "eval_samples_per_second": 521.444,
      "eval_steps_per_second": 4.088,
      "step": 11600
    },
    {
      "epoch": 5.882352941176471,
      "grad_norm": 1.9533092975616455,
      "learning_rate": 4.729661445174331e-05,
      "loss": 2.4782,
      "step": 11700
    },
    {
      "epoch": 5.932629462041227,
      "grad_norm": 1.9387785196304321,
      "learning_rate": 4.727134916624558e-05,
      "loss": 2.4807,
      "step": 11800
    },
    {
      "epoch": 5.932629462041227,
      "eval_loss": 2.6036009788513184,
      "eval_runtime": 25.7298,
      "eval_samples_per_second": 520.564,
      "eval_steps_per_second": 4.081,
      "step": 11800
    },
    {
      "epoch": 5.982905982905983,
      "grad_norm": 2.1405601501464844,
      "learning_rate": 4.7246083880747855e-05,
      "loss": 2.4646,
      "step": 11900
    },
    {
      "epoch": 6.033182503770739,
      "grad_norm": 1.9564601182937622,
      "learning_rate": 4.722081859525013e-05,
      "loss": 2.4042,
      "step": 12000
    },
    {
      "epoch": 6.033182503770739,
      "eval_loss": 2.6058692932128906,
      "eval_runtime": 25.5863,
      "eval_samples_per_second": 523.482,
      "eval_steps_per_second": 4.104,
      "step": 12000
    },
    {
      "epoch": 6.083459024635495,
      "grad_norm": 2.05240535736084,
      "learning_rate": 4.7195553309752404e-05,
      "loss": 2.3692,
      "step": 12100
    },
    {
      "epoch": 6.133735545500252,
      "grad_norm": 2.0756642818450928,
      "learning_rate": 4.717028802425468e-05,
      "loss": 2.3682,
      "step": 12200
    },
    {
      "epoch": 6.133735545500252,
      "eval_loss": 2.6088716983795166,
      "eval_runtime": 25.5953,
      "eval_samples_per_second": 523.3,
      "eval_steps_per_second": 4.102,
      "step": 12200
    },
    {
      "epoch": 6.184012066365008,
      "grad_norm": 39.51700973510742,
      "learning_rate": 4.714502273875695e-05,
      "loss": 2.3774,
      "step": 12300
    },
    {
      "epoch": 6.234288587229764,
      "grad_norm": 2.1020469665527344,
      "learning_rate": 4.711975745325922e-05,
      "loss": 2.3795,
      "step": 12400
    },
    {
      "epoch": 6.234288587229764,
      "eval_loss": 2.6093499660491943,
      "eval_runtime": 25.7267,
      "eval_samples_per_second": 520.627,
      "eval_steps_per_second": 4.081,
      "step": 12400
    },
    {
      "epoch": 6.28456510809452,
      "grad_norm": 2.040786027908325,
      "learning_rate": 4.70944921677615e-05,
      "loss": 2.387,
      "step": 12500
    },
    {
      "epoch": 6.334841628959276,
      "grad_norm": 2.916804552078247,
      "learning_rate": 4.7069226882263776e-05,
      "loss": 2.3926,
      "step": 12600
    },
    {
      "epoch": 6.334841628959276,
      "eval_loss": 2.6269636154174805,
      "eval_runtime": 25.5774,
      "eval_samples_per_second": 523.666,
      "eval_steps_per_second": 4.105,
      "step": 12600
    },
    {
      "epoch": 6.385118149824033,
      "grad_norm": 2.122878074645996,
      "learning_rate": 4.7043961596766044e-05,
      "loss": 2.4048,
      "step": 12700
    },
    {
      "epoch": 6.435394670688789,
      "grad_norm": 1.9385656118392944,
      "learning_rate": 4.701869631126832e-05,
      "loss": 2.3914,
      "step": 12800
    },
    {
      "epoch": 6.435394670688789,
      "eval_loss": 2.6061296463012695,
      "eval_runtime": 25.7181,
      "eval_samples_per_second": 520.801,
      "eval_steps_per_second": 4.083,
      "step": 12800
    },
    {
      "epoch": 6.4856711915535445,
      "grad_norm": 2.1312355995178223,
      "learning_rate": 4.699343102577059e-05,
      "loss": 2.3967,
      "step": 12900
    },
    {
      "epoch": 6.5359477124183005,
      "grad_norm": 2.09265398979187,
      "learning_rate": 4.696816574027287e-05,
      "loss": 2.4064,
      "step": 13000
    },
    {
      "epoch": 6.5359477124183005,
      "eval_loss": 2.6043012142181396,
      "eval_runtime": 25.6605,
      "eval_samples_per_second": 521.97,
      "eval_steps_per_second": 4.092,
      "step": 13000
    },
    {
      "epoch": 6.5862242332830565,
      "grad_norm": 2.3025388717651367,
      "learning_rate": 4.694290045477514e-05,
      "loss": 2.4022,
      "step": 13100
    },
    {
      "epoch": 6.6365007541478125,
      "grad_norm": 2.0716874599456787,
      "learning_rate": 4.6917635169277416e-05,
      "loss": 2.4032,
      "step": 13200
    },
    {
      "epoch": 6.6365007541478125,
      "eval_loss": 2.6047773361206055,
      "eval_runtime": 25.6767,
      "eval_samples_per_second": 521.64,
      "eval_steps_per_second": 4.089,
      "step": 13200
    },
    {
      "epoch": 6.686777275012569,
      "grad_norm": 2.111682415008545,
      "learning_rate": 4.689236988377969e-05,
      "loss": 2.4029,
      "step": 13300
    },
    {
      "epoch": 6.737053795877325,
      "grad_norm": 2.1282804012298584,
      "learning_rate": 4.6867104598281964e-05,
      "loss": 2.4058,
      "step": 13400
    },
    {
      "epoch": 6.737053795877325,
      "eval_loss": 2.5982682704925537,
      "eval_runtime": 25.7351,
      "eval_samples_per_second": 520.457,
      "eval_steps_per_second": 4.08,
      "step": 13400
    },
    {
      "epoch": 6.787330316742081,
      "grad_norm": 2.0022406578063965,
      "learning_rate": 4.684183931278424e-05,
      "loss": 2.4077,
      "step": 13500
    },
    {
      "epoch": 6.837606837606837,
      "grad_norm": 2.318403720855713,
      "learning_rate": 4.6816574027286506e-05,
      "loss": 2.4053,
      "step": 13600
    },
    {
      "epoch": 6.837606837606837,
      "eval_loss": 2.5995216369628906,
      "eval_runtime": 25.6835,
      "eval_samples_per_second": 521.502,
      "eval_steps_per_second": 4.088,
      "step": 13600
    },
    {
      "epoch": 6.887883358471594,
      "grad_norm": 2.246676445007324,
      "learning_rate": 4.679130874178879e-05,
      "loss": 2.4126,
      "step": 13700
    },
    {
      "epoch": 6.93815987933635,
      "grad_norm": 2.111175298690796,
      "learning_rate": 4.676604345629106e-05,
      "loss": 2.4141,
      "step": 13800
    },
    {
      "epoch": 6.93815987933635,
      "eval_loss": 2.596327066421509,
      "eval_runtime": 25.5941,
      "eval_samples_per_second": 523.324,
      "eval_steps_per_second": 4.103,
      "step": 13800
    },
    {
      "epoch": 6.988436400201106,
      "grad_norm": 2.134899139404297,
      "learning_rate": 4.674077817079333e-05,
      "loss": 2.4157,
      "step": 13900
    },
    {
      "epoch": 7.038712921065862,
      "grad_norm": 1.9639099836349487,
      "learning_rate": 4.6715512885295604e-05,
      "loss": 2.3292,
      "step": 14000
    },
    {
      "epoch": 7.038712921065862,
      "eval_loss": 2.604661703109741,
      "eval_runtime": 25.523,
      "eval_samples_per_second": 524.782,
      "eval_steps_per_second": 4.114,
      "step": 14000
    },
    {
      "epoch": 7.088989441930618,
      "grad_norm": 3.1631717681884766,
      "learning_rate": 4.6690247599797885e-05,
      "loss": 2.3026,
      "step": 14100
    },
    {
      "epoch": 7.139265962795375,
      "grad_norm": 2.1753034591674805,
      "learning_rate": 4.666498231430015e-05,
      "loss": 2.3136,
      "step": 14200
    },
    {
      "epoch": 7.139265962795375,
      "eval_loss": 2.6067891120910645,
      "eval_runtime": 25.5465,
      "eval_samples_per_second": 524.299,
      "eval_steps_per_second": 4.11,
      "step": 14200
    },
    {
      "epoch": 7.189542483660131,
      "grad_norm": 2.416159152984619,
      "learning_rate": 4.663971702880243e-05,
      "loss": 2.3148,
      "step": 14300
    },
    {
      "epoch": 7.239819004524887,
      "grad_norm": 2.388368844985962,
      "learning_rate": 4.66144517433047e-05,
      "loss": 2.3225,
      "step": 14400
    },
    {
      "epoch": 7.239819004524887,
      "eval_loss": 2.607954978942871,
      "eval_runtime": 25.6698,
      "eval_samples_per_second": 521.781,
      "eval_steps_per_second": 4.09,
      "step": 14400
    },
    {
      "epoch": 7.290095525389643,
      "grad_norm": 2.2972562313079834,
      "learning_rate": 4.6589186457806976e-05,
      "loss": 2.3189,
      "step": 14500
    },
    {
      "epoch": 7.340372046254399,
      "grad_norm": 2.180652379989624,
      "learning_rate": 4.656392117230925e-05,
      "loss": 2.3254,
      "step": 14600
    },
    {
      "epoch": 7.340372046254399,
      "eval_loss": 2.6077494621276855,
      "eval_runtime": 25.6237,
      "eval_samples_per_second": 522.719,
      "eval_steps_per_second": 4.098,
      "step": 14600
    },
    {
      "epoch": 7.390648567119156,
      "grad_norm": 2.592958688735962,
      "learning_rate": 4.6538655886811524e-05,
      "loss": 2.3392,
      "step": 14700
    },
    {
      "epoch": 7.440925087983912,
      "grad_norm": 3.212287425994873,
      "learning_rate": 4.651339060131379e-05,
      "loss": 2.3386,
      "step": 14800
    },
    {
      "epoch": 7.440925087983912,
      "eval_loss": 2.6130239963531494,
      "eval_runtime": 25.8024,
      "eval_samples_per_second": 519.098,
      "eval_steps_per_second": 4.069,
      "step": 14800
    },
    {
      "epoch": 7.491201608848668,
      "grad_norm": 2.554809093475342,
      "learning_rate": 4.648812531581607e-05,
      "loss": 2.3321,
      "step": 14900
    },
    {
      "epoch": 7.541478129713424,
      "grad_norm": 3.382845640182495,
      "learning_rate": 4.646286003031835e-05,
      "loss": 2.3375,
      "step": 15000
    },
    {
      "epoch": 7.541478129713424,
      "eval_loss": 2.605121612548828,
      "eval_runtime": 25.9618,
      "eval_samples_per_second": 515.911,
      "eval_steps_per_second": 4.044,
      "step": 15000
    },
    {
      "epoch": 7.59175465057818,
      "grad_norm": 2.3170108795166016,
      "learning_rate": 4.6437594744820615e-05,
      "loss": 2.3442,
      "step": 15100
    },
    {
      "epoch": 7.6420311714429365,
      "grad_norm": 2.9262006282806396,
      "learning_rate": 4.6412329459322896e-05,
      "loss": 2.3429,
      "step": 15200
    },
    {
      "epoch": 7.6420311714429365,
      "eval_loss": 2.606152296066284,
      "eval_runtime": 25.5867,
      "eval_samples_per_second": 523.474,
      "eval_steps_per_second": 4.104,
      "step": 15200
    },
    {
      "epoch": 7.6923076923076925,
      "grad_norm": 2.17834210395813,
      "learning_rate": 4.638706417382517e-05,
      "loss": 2.3504,
      "step": 15300
    },
    {
      "epoch": 7.7425842131724485,
      "grad_norm": 2.8113861083984375,
      "learning_rate": 4.636179888832744e-05,
      "loss": 2.349,
      "step": 15400
    },
    {
      "epoch": 7.7425842131724485,
      "eval_loss": 2.602391242980957,
      "eval_runtime": 25.6949,
      "eval_samples_per_second": 521.272,
      "eval_steps_per_second": 4.086,
      "step": 15400
    },
    {
      "epoch": 7.7928607340372045,
      "grad_norm": 2.372715473175049,
      "learning_rate": 4.633653360282971e-05,
      "loss": 2.3554,
      "step": 15500
    },
    {
      "epoch": 7.8431372549019605,
      "grad_norm": 2.5967626571655273,
      "learning_rate": 4.6311268317331994e-05,
      "loss": 2.3583,
      "step": 15600
    },
    {
      "epoch": 7.8431372549019605,
      "eval_loss": 2.5996267795562744,
      "eval_runtime": 25.6565,
      "eval_samples_per_second": 522.051,
      "eval_steps_per_second": 4.093,
      "step": 15600
    },
    {
      "epoch": 7.893413775766717,
      "grad_norm": 2.2408108711242676,
      "learning_rate": 4.628600303183426e-05,
      "loss": 2.3631,
      "step": 15700
    },
    {
      "epoch": 7.943690296631473,
      "grad_norm": 2.2527222633361816,
      "learning_rate": 4.6260737746336536e-05,
      "loss": 2.3692,
      "step": 15800
    },
    {
      "epoch": 7.943690296631473,
      "eval_loss": 2.5971217155456543,
      "eval_runtime": 25.5956,
      "eval_samples_per_second": 523.293,
      "eval_steps_per_second": 4.102,
      "step": 15800
    },
    {
      "epoch": 7.993966817496229,
      "grad_norm": 2.146538257598877,
      "learning_rate": 4.623547246083881e-05,
      "loss": 2.3596,
      "step": 15900
    },
    {
      "epoch": 8.044243338360985,
      "grad_norm": 2.7363271713256836,
      "learning_rate": 4.6210207175341085e-05,
      "loss": 2.2538,
      "step": 16000
    },
    {
      "epoch": 8.044243338360985,
      "eval_loss": 2.6104209423065186,
      "eval_runtime": 25.6362,
      "eval_samples_per_second": 522.465,
      "eval_steps_per_second": 4.096,
      "step": 16000
    },
    {
      "epoch": 8.094519859225741,
      "grad_norm": 2.4441723823547363,
      "learning_rate": 4.618494188984336e-05,
      "loss": 2.2366,
      "step": 16100
    },
    {
      "epoch": 8.144796380090497,
      "grad_norm": 2.618699550628662,
      "learning_rate": 4.615967660434563e-05,
      "loss": 2.2462,
      "step": 16200
    },
    {
      "epoch": 8.144796380090497,
      "eval_loss": 2.6114275455474854,
      "eval_runtime": 25.6665,
      "eval_samples_per_second": 521.848,
      "eval_steps_per_second": 4.091,
      "step": 16200
    },
    {
      "epoch": 8.195072900955253,
      "grad_norm": 2.2446534633636475,
      "learning_rate": 4.61344113188479e-05,
      "loss": 2.2558,
      "step": 16300
    },
    {
      "epoch": 8.24534942182001,
      "grad_norm": 2.6342623233795166,
      "learning_rate": 4.610914603335018e-05,
      "loss": 2.2579,
      "step": 16400
    },
    {
      "epoch": 8.24534942182001,
      "eval_loss": 2.6179544925689697,
      "eval_runtime": 25.6845,
      "eval_samples_per_second": 521.482,
      "eval_steps_per_second": 4.088,
      "step": 16400
    },
    {
      "epoch": 8.295625942684767,
      "grad_norm": 2.7218472957611084,
      "learning_rate": 4.6083880747852456e-05,
      "loss": 2.2613,
      "step": 16500
    },
    {
      "epoch": 8.345902463549523,
      "grad_norm": 2.2242088317871094,
      "learning_rate": 4.6058615462354724e-05,
      "loss": 2.2794,
      "step": 16600
    },
    {
      "epoch": 8.345902463549523,
      "eval_loss": 2.6191697120666504,
      "eval_runtime": 25.5958,
      "eval_samples_per_second": 523.288,
      "eval_steps_per_second": 4.102,
      "step": 16600
    },
    {
      "epoch": 8.396178984414279,
      "grad_norm": 2.2761306762695312,
      "learning_rate": 4.6033350176857e-05,
      "loss": 2.276,
      "step": 16700
    },
    {
      "epoch": 8.446455505279035,
      "grad_norm": 2.5047900676727295,
      "learning_rate": 4.600808489135928e-05,
      "loss": 2.2745,
      "step": 16800
    },
    {
      "epoch": 8.446455505279035,
      "eval_loss": 2.617962598800659,
      "eval_runtime": 25.6637,
      "eval_samples_per_second": 521.905,
      "eval_steps_per_second": 4.091,
      "step": 16800
    },
    {
      "epoch": 8.49673202614379,
      "grad_norm": 2.140636920928955,
      "learning_rate": 4.598281960586155e-05,
      "loss": 2.2872,
      "step": 16900
    },
    {
      "epoch": 8.547008547008547,
      "grad_norm": 2.5986380577087402,
      "learning_rate": 4.595755432036382e-05,
      "loss": 2.2826,
      "step": 17000
    },
    {
      "epoch": 8.547008547008547,
      "eval_loss": 2.6117196083068848,
      "eval_runtime": 25.6618,
      "eval_samples_per_second": 521.944,
      "eval_steps_per_second": 4.092,
      "step": 17000
    },
    {
      "epoch": 8.597285067873303,
      "grad_norm": 2.4697933197021484,
      "learning_rate": 4.5932289034866096e-05,
      "loss": 2.2836,
      "step": 17100
    },
    {
      "epoch": 8.647561588738059,
      "grad_norm": 2.380697011947632,
      "learning_rate": 4.590702374936837e-05,
      "loss": 2.2848,
      "step": 17200
    },
    {
      "epoch": 8.647561588738059,
      "eval_loss": 2.608520269393921,
      "eval_runtime": 25.5843,
      "eval_samples_per_second": 523.525,
      "eval_steps_per_second": 4.104,
      "step": 17200
    },
    {
      "epoch": 8.697838109602815,
      "grad_norm": 4.0892744064331055,
      "learning_rate": 4.5881758463870645e-05,
      "loss": 2.2956,
      "step": 17300
    },
    {
      "epoch": 8.748114630467573,
      "grad_norm": 2.269582509994507,
      "learning_rate": 4.585649317837292e-05,
      "loss": 2.298,
      "step": 17400
    },
    {
      "epoch": 8.748114630467573,
      "eval_loss": 2.608729362487793,
      "eval_runtime": 25.6303,
      "eval_samples_per_second": 522.585,
      "eval_steps_per_second": 4.097,
      "step": 17400
    },
    {
      "epoch": 8.798391151332329,
      "grad_norm": 2.393477439880371,
      "learning_rate": 4.583122789287519e-05,
      "loss": 2.2965,
      "step": 17500
    },
    {
      "epoch": 8.848667672197084,
      "grad_norm": 2.3168818950653076,
      "learning_rate": 4.580596260737747e-05,
      "loss": 2.3019,
      "step": 17600
    },
    {
      "epoch": 8.848667672197084,
      "eval_loss": 2.607645273208618,
      "eval_runtime": 25.6471,
      "eval_samples_per_second": 522.243,
      "eval_steps_per_second": 4.094,
      "step": 17600
    },
    {
      "epoch": 8.89894419306184,
      "grad_norm": 2.688844680786133,
      "learning_rate": 4.578069732187974e-05,
      "loss": 2.3055,
      "step": 17700
    },
    {
      "epoch": 8.949220713926596,
      "grad_norm": 2.8452036380767822,
      "learning_rate": 4.575543203638201e-05,
      "loss": 2.2995,
      "step": 17800
    },
    {
      "epoch": 8.949220713926596,
      "eval_loss": 2.6029369831085205,
      "eval_runtime": 25.6458,
      "eval_samples_per_second": 522.269,
      "eval_steps_per_second": 4.094,
      "step": 17800
    },
    {
      "epoch": 8.999497234791352,
      "grad_norm": 2.4645259380340576,
      "learning_rate": 4.5730166750884284e-05,
      "loss": 2.3012,
      "step": 17900
    },
    {
      "epoch": 9.049773755656108,
      "grad_norm": 2.3608341217041016,
      "learning_rate": 4.5704901465386565e-05,
      "loss": 2.1847,
      "step": 18000
    },
    {
      "epoch": 9.049773755656108,
      "eval_loss": 2.6140670776367188,
      "eval_runtime": 25.553,
      "eval_samples_per_second": 524.166,
      "eval_steps_per_second": 4.109,
      "step": 18000
    },
    {
      "epoch": 9.100050276520864,
      "grad_norm": 2.4211418628692627,
      "learning_rate": 4.567963617988883e-05,
      "loss": 2.1773,
      "step": 18100
    },
    {
      "epoch": 9.15032679738562,
      "grad_norm": 146.6725311279297,
      "learning_rate": 4.565437089439111e-05,
      "loss": 2.181,
      "step": 18200
    },
    {
      "epoch": 9.15032679738562,
      "eval_loss": 2.623861312866211,
      "eval_runtime": 25.6156,
      "eval_samples_per_second": 522.885,
      "eval_steps_per_second": 4.099,
      "step": 18200
    },
    {
      "epoch": 9.200603318250376,
      "grad_norm": 2.371424436569214,
      "learning_rate": 4.562910560889338e-05,
      "loss": 2.191,
      "step": 18300
    },
    {
      "epoch": 9.250879839115132,
      "grad_norm": 2.3911144733428955,
      "learning_rate": 4.5603840323395656e-05,
      "loss": 2.2013,
      "step": 18400
    },
    {
      "epoch": 9.250879839115132,
      "eval_loss": 2.624997854232788,
      "eval_runtime": 25.5937,
      "eval_samples_per_second": 523.332,
      "eval_steps_per_second": 4.103,
      "step": 18400
    },
    {
      "epoch": 9.30115635997989,
      "grad_norm": 2.3287105560302734,
      "learning_rate": 4.557857503789793e-05,
      "loss": 2.2109,
      "step": 18500
    },
    {
      "epoch": 9.351432880844646,
      "grad_norm": 2.4340898990631104,
      "learning_rate": 4.5553309752400205e-05,
      "loss": 2.2146,
      "step": 18600
    },
    {
      "epoch": 9.351432880844646,
      "eval_loss": 2.6257667541503906,
      "eval_runtime": 25.6632,
      "eval_samples_per_second": 521.914,
      "eval_steps_per_second": 4.091,
      "step": 18600
    },
    {
      "epoch": 9.401709401709402,
      "grad_norm": 3.7937605381011963,
      "learning_rate": 4.552804446690248e-05,
      "loss": 2.2183,
      "step": 18700
    },
    {
      "epoch": 9.451985922574158,
      "grad_norm": 2.515960216522217,
      "learning_rate": 4.5502779181404754e-05,
      "loss": 2.2122,
      "step": 18800
    },
    {
      "epoch": 9.451985922574158,
      "eval_loss": 2.6261346340179443,
      "eval_runtime": 25.6341,
      "eval_samples_per_second": 522.507,
      "eval_steps_per_second": 4.096,
      "step": 18800
    },
    {
      "epoch": 9.502262443438914,
      "grad_norm": 2.4153637886047363,
      "learning_rate": 4.547751389590703e-05,
      "loss": 2.2187,
      "step": 18900
    },
    {
      "epoch": 9.55253896430367,
      "grad_norm": 2.43333101272583,
      "learning_rate": 4.5452248610409296e-05,
      "loss": 2.2275,
      "step": 19000
    },
    {
      "epoch": 9.55253896430367,
      "eval_loss": 2.617504358291626,
      "eval_runtime": 25.5665,
      "eval_samples_per_second": 523.888,
      "eval_steps_per_second": 4.107,
      "step": 19000
    },
    {
      "epoch": 9.602815485168426,
      "grad_norm": 2.5289499759674072,
      "learning_rate": 4.542698332491158e-05,
      "loss": 2.231,
      "step": 19100
    },
    {
      "epoch": 9.653092006033182,
      "grad_norm": 3.7970211505889893,
      "learning_rate": 4.540171803941385e-05,
      "loss": 2.2296,
      "step": 19200
    },
    {
      "epoch": 9.653092006033182,
      "eval_loss": 2.621351957321167,
      "eval_runtime": 25.6809,
      "eval_samples_per_second": 521.554,
      "eval_steps_per_second": 4.089,
      "step": 19200
    },
    {
      "epoch": 9.703368526897938,
      "grad_norm": 7.051069736480713,
      "learning_rate": 4.537645275391612e-05,
      "loss": 2.2375,
      "step": 19300
    },
    {
      "epoch": 9.753645047762696,
      "grad_norm": 2.630920886993408,
      "learning_rate": 4.535118746841839e-05,
      "loss": 2.2371,
      "step": 19400
    },
    {
      "epoch": 9.753645047762696,
      "eval_loss": 2.624053716659546,
      "eval_runtime": 25.5656,
      "eval_samples_per_second": 523.908,
      "eval_steps_per_second": 4.107,
      "step": 19400
    },
    {
      "epoch": 9.803921568627452,
      "grad_norm": 149.43467712402344,
      "learning_rate": 4.5325922182920674e-05,
      "loss": 2.2341,
      "step": 19500
    },
    {
      "epoch": 9.854198089492208,
      "grad_norm": 2.5964272022247314,
      "learning_rate": 4.530065689742294e-05,
      "loss": 2.2428,
      "step": 19600
    },
    {
      "epoch": 9.854198089492208,
      "eval_loss": 2.617743968963623,
      "eval_runtime": 25.5573,
      "eval_samples_per_second": 524.078,
      "eval_steps_per_second": 4.108,
      "step": 19600
    },
    {
      "epoch": 9.904474610356964,
      "grad_norm": 2.4297966957092285,
      "learning_rate": 4.5275391611925216e-05,
      "loss": 2.2497,
      "step": 19700
    },
    {
      "epoch": 9.95475113122172,
      "grad_norm": 6.295304298400879,
      "learning_rate": 4.525012632642749e-05,
      "loss": 2.2454,
      "step": 19800
    },
    {
      "epoch": 9.95475113122172,
      "eval_loss": 2.617191791534424,
      "eval_runtime": 25.6277,
      "eval_samples_per_second": 522.637,
      "eval_steps_per_second": 4.097,
      "step": 19800
    },
    {
      "epoch": 10.005027652086476,
      "grad_norm": 2.9537010192871094,
      "learning_rate": 4.5224861040929765e-05,
      "loss": 2.2267,
      "step": 19900
    },
    {
      "epoch": 10.055304172951232,
      "grad_norm": 2.394456386566162,
      "learning_rate": 4.519959575543204e-05,
      "loss": 2.0976,
      "step": 20000
    },
    {
      "epoch": 10.055304172951232,
      "eval_loss": 2.6357345581054688,
      "eval_runtime": 25.5836,
      "eval_samples_per_second": 523.538,
      "eval_steps_per_second": 4.104,
      "step": 20000
    },
    {
      "epoch": 10.105580693815988,
      "grad_norm": 2.692195415496826,
      "learning_rate": 4.5174330469934314e-05,
      "loss": 2.1126,
      "step": 20100
    },
    {
      "epoch": 10.155857214680744,
      "grad_norm": 2.6597697734832764,
      "learning_rate": 4.514906518443658e-05,
      "loss": 2.1254,
      "step": 20200
    },
    {
      "epoch": 10.155857214680744,
      "eval_loss": 2.6382195949554443,
      "eval_runtime": 25.5652,
      "eval_samples_per_second": 523.915,
      "eval_steps_per_second": 4.107,
      "step": 20200
    },
    {
      "epoch": 10.2061337355455,
      "grad_norm": 8.701390266418457,
      "learning_rate": 4.512379989893886e-05,
      "loss": 2.1225,
      "step": 20300
    },
    {
      "epoch": 10.256410256410255,
      "grad_norm": 3.1761744022369385,
      "learning_rate": 4.509853461344114e-05,
      "loss": 2.1293,
      "step": 20400
    },
    {
      "epoch": 10.256410256410255,
      "eval_loss": 2.6459100246429443,
      "eval_runtime": 25.6092,
      "eval_samples_per_second": 523.015,
      "eval_steps_per_second": 4.1,
      "step": 20400
    },
    {
      "epoch": 10.306686777275013,
      "grad_norm": 2.6772234439849854,
      "learning_rate": 4.5073269327943404e-05,
      "loss": 2.1385,
      "step": 20500
    },
    {
      "epoch": 10.35696329813977,
      "grad_norm": 2.5921740531921387,
      "learning_rate": 4.504800404244568e-05,
      "loss": 2.1487,
      "step": 20600
    },
    {
      "epoch": 10.35696329813977,
      "eval_loss": 2.641395092010498,
      "eval_runtime": 25.6341,
      "eval_samples_per_second": 522.507,
      "eval_steps_per_second": 4.096,
      "step": 20600
    },
    {
      "epoch": 10.407239819004525,
      "grad_norm": 2.5481700897216797,
      "learning_rate": 4.502273875694796e-05,
      "loss": 2.145,
      "step": 20700
    },
    {
      "epoch": 10.457516339869281,
      "grad_norm": 3.128413677215576,
      "learning_rate": 4.499747347145023e-05,
      "loss": 2.1579,
      "step": 20800
    },
    {
      "epoch": 10.457516339869281,
      "eval_loss": 2.6409451961517334,
      "eval_runtime": 25.6084,
      "eval_samples_per_second": 523.032,
      "eval_steps_per_second": 4.1,
      "step": 20800
    },
    {
      "epoch": 10.507792860734037,
      "grad_norm": 2.8630740642547607,
      "learning_rate": 4.49722081859525e-05,
      "loss": 2.1612,
      "step": 20900
    },
    {
      "epoch": 10.558069381598793,
      "grad_norm": 2.691403388977051,
      "learning_rate": 4.4946942900454776e-05,
      "loss": 2.1553,
      "step": 21000
    },
    {
      "epoch": 10.558069381598793,
      "eval_loss": 2.638070821762085,
      "eval_runtime": 25.574,
      "eval_samples_per_second": 523.734,
      "eval_steps_per_second": 4.106,
      "step": 21000
    },
    {
      "epoch": 10.60834590246355,
      "grad_norm": 2.7394161224365234,
      "learning_rate": 4.492167761495705e-05,
      "loss": 2.1615,
      "step": 21100
    },
    {
      "epoch": 10.658622423328305,
      "grad_norm": 3.99531888961792,
      "learning_rate": 4.4896412329459325e-05,
      "loss": 2.1669,
      "step": 21200
    },
    {
      "epoch": 10.658622423328305,
      "eval_loss": 2.6375160217285156,
      "eval_runtime": 25.6267,
      "eval_samples_per_second": 522.658,
      "eval_steps_per_second": 4.097,
      "step": 21200
    },
    {
      "epoch": 10.708898944193061,
      "grad_norm": 2.583310127258301,
      "learning_rate": 4.48711470439616e-05,
      "loss": 2.1749,
      "step": 21300
    },
    {
      "epoch": 10.759175465057819,
      "grad_norm": 2.667572498321533,
      "learning_rate": 4.484588175846387e-05,
      "loss": 2.1735,
      "step": 21400
    },
    {
      "epoch": 10.759175465057819,
      "eval_loss": 2.632610321044922,
      "eval_runtime": 25.5957,
      "eval_samples_per_second": 523.291,
      "eval_steps_per_second": 4.102,
      "step": 21400
    },
    {
      "epoch": 10.809451985922575,
      "grad_norm": 5.7480363845825195,
      "learning_rate": 4.482061647296615e-05,
      "loss": 2.1771,
      "step": 21500
    }
  ],
  "logging_steps": 100,
  "max_steps": 198900,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 100,
  "save_steps": 250,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.9285990187136e+17,
  "train_batch_size": 128,
  "trial_name": null,
  "trial_params": null
}
